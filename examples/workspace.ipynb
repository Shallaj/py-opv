{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyOPV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting latest DICOM Standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyopv import get_dicom_standard # if you run this cell, you will get the latest SAP DICOM standard\n",
    "get_dicom_standard() # if you run this cell, you will get the latest SAP DICOM standard and writes in a csv file in the same directory as this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking missing tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'sample_files/SD1031_20230914_OD_OPV.dcm'  # add file path here e.g. data/MY_OPV_FILE.dcm\n",
    "\n",
    "m_opvdicom = pyopv.read_dicom(file_path)\n",
    "missing_count, missingtag_df = m_opvdicom.check_missing_tags()\n",
    "missingtag_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entire directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_opvdicoms = pyopv.read_dicom_directory('sample_files', file_extension='dcm')\n",
    "missingtags_df = m_opvdicoms.check_missing_tags()\n",
    "missingtags_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting OPV DICOM to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*#* This snippet converts the entire dicom file into a very long pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyopv import dicom_to_dataframe\n",
    "\n",
    "file_path = 'sample_files/SD1031_20230914_OD_OPV.dcm'  # add file path here e.g. data/MY_OPV_FILE.dcm\n",
    "dicom_df = dicom_to_dataframe(file_path)\n",
    "dicom_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON conversion\n",
    "* this snippet will be updated in future versions to accomodate FHIR IG because that IG is not currently available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "\n",
    "file_path = 'sample_files/SD1031_20230914_OD_OPV.dcm' # add file path here e.g. data/MY_OPV_FILE.dcm\n",
    "ds = pydicom.dcmread(file_path)\n",
    "json = ds.to_json_dict()\n",
    "json['00080080']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nested values\n",
    "json = ds.to_json_dict()\n",
    "points = json['00240089']['Value'][0]['00240097']\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting pointwise data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_opvdicom = pyopv.read_dicom('sample_files/SD1031_20230914_OD_OPV.dcm')\n",
    "\n",
    "pointwise_data = m_opvdicom.pointwise_to_pandas()\n",
    "pointwise_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entire directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_opvdicoms = pyopv.read_dicom_directory('/Users/shahinh/Downloads/OneDrive_1_7-2-2024/SD4132_20240610_OPVtest', file_extension='dcm')\n",
    "\n",
    "pointwise_data, error_df = m_opvdicoms.pointwise_to_pandas()\n",
    "pointwise_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'pointwise_data' is already defined as a DataFrame\n",
    "x_coord = pointwise_data['x_coords']\n",
    "y_coord = pointwise_data['y_coords']\n",
    "\n",
    "ns_pointwise_data = pointwise_data.copy()\n",
    "\n",
    "# Mapping to NS system\n",
    "# Flip x coordinates for left laterality\n",
    "ns_pointwise_data.loc[ns_pointwise_data['laterality'] == 'L', 'x_coords'] = -1 * ns_pointwise_data['x_coords']\n",
    "\n",
    "# Function to map x coordinates to NS system\n",
    "def map_ns_x(row):\n",
    "    x_coord = int(row['x_coords'])\n",
    "    if x_coord > 0:\n",
    "        return f'T{abs(x_coord)}_'\n",
    "    else:\n",
    "        return f'N{abs(x_coord)}_'\n",
    "\n",
    "# Apply the function to create the 'ns' column\n",
    "ns_pointwise_data['ns'] = ns_pointwise_data.apply(map_ns_x, axis=1)\n",
    "\n",
    "# Function to map y coordinates to IS system\n",
    "def map_ns_y(y):\n",
    "    y_coord = int(y)\n",
    "    if y_coord < 0:\n",
    "        return f'I{abs(y_coord)}'\n",
    "    else:\n",
    "        return f'S{y_coord}'\n",
    "\n",
    "# Apply the function to append y coordinates to the 'ns' column\n",
    "ns_pointwise_data['ns'] = ns_pointwise_data['ns'] + ns_pointwise_data['y_coords'].apply(map_ns_y)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "ns_pointwise_data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping original column names to Humphrey Visual Field equivalents\n",
    "opv_hfa_dict = {\n",
    "    'sensitivity_values': 'threshold',\n",
    "    'age_corrected_sensitivity_deviation_values': 'total_deviation',\n",
    "    'age_corrected_sensitivity_deviation_probability_values': 'total_deviation_probability',\n",
    "    'generalized_defect_corrected_sensitivity_deviation_flag': 'generalized_defect_threshold_deviation_flag',\n",
    "    'generalized_defect_corrected_sensitivity_values': 'pattern_deviation',\n",
    "    'generalized_defect_corrected_sensitivity_probability_values': 'pattern_deviation_probability',\n",
    "    'ns': 'nasal_temporal_superior_inferior'\n",
    "}\n",
    "\n",
    "# Assuming 'pointwise_data' is your DataFrame, you can rename the columns using this dictionary\n",
    "ns_pointwise_data.rename(columns=opv_hfa_dict, inplace=True)\n",
    "\n",
    "# Display the modified DataFrame to ensure the changes are correct\n",
    "ns_pointwise_data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping humphrey equivalent to ucsd equivalent\n",
    "hfa_ucsd_dict = {\n",
    "    'threshold': 'Thr',\n",
    "    'total_deviation': 'TD',\n",
    "    'total_deviation_probability': 'TDP',\n",
    "    'generalized_defect_threshold_deviation_flag': 'generalized_defect_corrected_sensitivity_deviation_flag',\n",
    "    'pattern_deviation': 'PD',\n",
    "    'pattern_deviation_probability': 'PDP',\n",
    "    'nasal_temporal_superior_inferior': 'ns'\n",
    "}\n",
    "\n",
    "# Assuming 'pointwise_data' is your DataFrame, you can rename the columns using this dictionary\n",
    "ns_pointwise_data.rename(columns=hfa_ucsd_dict, inplace=True)\n",
    "\n",
    "# Display the modified DataFrame to ensure the changes are correct\n",
    "ns_pointwise_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing pointwise data into JSON\n",
    "* Single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyopv import pointwise_to_nested_json\n",
    "file_path = 'sample_files/SD1031_20230914_OD_OPV.dcm' # add file path here e.g. data/MY_OPV_FILE.dcm\n",
    "nested_json = pointwise_to_nested_json(file_path)\n",
    "nested_json['SD1031']['R']['1.2.276.0.75.2.5.80.25.3.231115115903087.345048637379.415558310'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example conversion of a JSON resource to pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.json_normalize(nested_json['SD1031']['R']['1.2.276.0.75.2.5.80.25.3.231115115903087.345048637379.415558310'], sep='_').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bulk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyopv import opvdicoms_pointwise_to_nested_json \n",
    "\n",
    "directory_path = 'sample_files' # add directory path here e.g. data\n",
    "\n",
    "# Run the function and get the nested JSON\n",
    "bulk_pointwise_nested_json = opvdicoms_pointwise_to_nested_json(directory_path)\n",
    "\n",
    "# convert the nested JSON so that the keys are the patient IDs\n",
    "\n",
    "\n",
    "bulk_pointwise_nested_json['SD1031']['R']['1.2.276.0.75.2.5.80.25.3.221018115130492.345048637379.430073977'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.normalize the nested JSON\n",
    "bulk_pointwise_nested_json['503286']['L']['2.25.131336704941307872492978734319609842773'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(bulk_pointwise_nested_json['503286']['L']['2.25.131336704941307872492978734319609842773']).head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
